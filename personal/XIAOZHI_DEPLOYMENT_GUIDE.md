# XiaoZhi ESP32 Server - Complete Deployment Guide

> **M·ª•c ƒë√≠ch**: H∆∞·ªõng d·∫´n chi ti·∫øt tri·ªÉn khai server XiaoZhi t·ª´ source code cho ESP32-C3 robot
> 
> **C·∫•u h√¨nh h·ªá th·ªëng**: Ubuntu PC - 6 cores, 16GB RAM, GTX 1060 6GB
> 
> **Chi·∫øn l∆∞·ª£c**: ASR & TTS local, LLM qua Gemini API

---

## üìã M·ª§C L·ª§C

1. [C√†i ƒë·∫∑t t·ª´ Source](#1-c√†i-ƒë·∫∑t-t·ª´-source)
2. [Ki·∫øn tr√∫c Source Code](#2-ki·∫øn-tr√∫c-source-code)
3. [Configuration & Customization](#3-configuration--customization)
4. [ESP32-C3 Configuration](#4-esp32-c3-configuration)
5. [Troubleshooting & Performance](#5-troubleshooting--performance)

---

## 1. C√ÄI ƒê·∫∂T T·ª™ SOURCE

### 1.1. Chu·∫©n b·ªã m√¥i tr∆∞·ªùng

#### 1.1.1. Ki·ªÉm tra CUDA (cho GPU acceleration)

```bash
# Ki·ªÉm tra CUDA ƒë√£ c√†i ch∆∞a
nvidia-smi

# Ki·ªÉm tra CUDA version
nvcc --version

# N·∫øu ch∆∞a c√≥ CUDA, c√†i ƒë·∫∑t CUDA 11.8 ho·∫∑c 12.1
# Ubuntu 22.04:
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda-toolkit-11-8

# Th√™m v√†o ~/.bashrc
echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

#### 1.1.2. C√†i ƒë·∫∑t Conda

```bash
# Download Miniconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

# C√†i ƒë·∫∑t
bash Miniconda3-latest-Linux-x86_64.sh

# Reload shell
source ~/.bashrc

# Verify
conda --version
```

#### 1.1.3. T·∫°o m√¥i tr∆∞·ªùng Python

```bash
# T·∫°o m√¥i tr∆∞·ªùng m·ªõi
conda create -n xiaozhi python=3.10 -y
conda activate xiaozhi

# C√†i c√°c dependencies h·ªá th·ªëng quan tr·ªçng
conda install libopus ffmpeg -y

# Linux specific: C√†i th√™m libiconv n·∫øu c·∫ßn
conda install libiconv -y
```

### 1.2. Clone source code

```bash
# Clone repository
cd ~/Desktop/RD
git clone https://github.com/xinnan-tech/xiaozhi-esp32-server.git
cd xiaozhi-esp32-server/main/xiaozhi-server

# Ki·ªÉm tra c·∫•u tr√∫c
ls -la
```

### 1.3. C√†i ƒë·∫∑t Python dependencies

```bash
# ƒê·∫£m b·∫£o ƒëang trong m√¥i tr∆∞·ªùng conda
conda activate xiaozhi

# C√†i PyTorch v·ªõi CUDA support
# Cho GTX 1060 (CUDA 11.8 compatible)
pip install torch==2.2.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu118

# Verify PyTorch GPU
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}'); print(f'Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else None}')"

# K·∫øt qu·∫£ mong ƒë·ª£i:
# CUDA available: True
# CUDA version: 11.8
# Device: NVIDIA GeForce GTX 1060 6GB

# C√†i c√°c dependencies c√≤n l·∫°i
pip install -r requirements.txt
```

### 1.4. T·∫£i ASR model (FunASR)

```bash
# T·∫°o th∆∞ m·ª•c models
mkdir -p models/SenseVoiceSmall

# T·∫£i model SenseVoiceSmall (~400MB)
# Option 1: T·ª´ ModelScope (recommended)
cd models/SenseVoiceSmall
wget https://modelscope.cn/models/iic/SenseVoiceSmall/resolve/master/model.pt

# Option 2: N·∫øu link tr√™n ch·∫≠m, d√πng mirror
wget https://hf-mirror.com/FunAudioLLM/SenseVoiceSmall/resolve/main/model.pt

# Verify
ls -lh model.pt
# K·∫øt qu·∫£: ~395MB

cd ../..
```

### 1.5. T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c

```bash
# T·∫°o c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt
mkdir -p data tmp music

# Verify
tree -L 1
# K·∫øt qu·∫£:
# .
# ‚îú‚îÄ‚îÄ app.py
# ‚îú‚îÄ‚îÄ config.yaml
# ‚îú‚îÄ‚îÄ data/
# ‚îú‚îÄ‚îÄ models/
# ‚îú‚îÄ‚îÄ tmp/
# ‚îú‚îÄ‚îÄ music/
# ‚îú‚îÄ‚îÄ core/
# ‚îî‚îÄ‚îÄ ...
```

### 1.6. T·∫°o file c·∫•u h√¨nh

```bash
# T·∫°o file .config.yaml trong th∆∞ m·ª•c data
touch data/.config.yaml
```

> **L∆∞u √Ω**: N·ªôi dung file `.config.yaml` s·∫Ω ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p chi ti·∫øt ·ªü [Ph·∫ßn 3](#3-configuration--customization)

---

## 2. KI·∫æN TR√öC SOURCE CODE

### 2.1. S∆° ƒë·ªì t·ªïng quan

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        ESP32-C3 Robot                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ   MIC    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  AUDIO   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ WebSocket‚îÇ              ‚îÇ
‚îÇ  ‚îÇ          ‚îÇ    ‚îÇ ENCODER  ‚îÇ    ‚îÇ  Client  ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ (OPUS)   ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                        ‚îÇ WS://ip:8000/xiaozhi/v1/
                                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              XiaoZhi Server (Ubuntu PC)                      ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ              WebSocket Server (Port 8000)              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                  (core/websocket_server.py)            ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                   ‚îÇ                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ              Connection Handler                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ              (core/connection.py)                       ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                   ‚îÇ                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ     Audio Processing Pipeline (core/handle/)           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  1. VAD (Voice Activity Detection)                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     ‚îî‚îÄ‚ñ∂ SileroVAD (models/snakers4_silero-vad)        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  2. ASR (Speech Recognition)                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     ‚îî‚îÄ‚ñ∂ FunASR (models/SenseVoiceSmall) [GPU]         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  3. Intent Recognition                                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     ‚îî‚îÄ‚ñ∂ function_call (plugins_func/functions/)        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  4. LLM (Language Model)                               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     ‚îî‚îÄ‚ñ∂ Gemini API (google-generativeai)              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  5. TTS (Text-to-Speech)                               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     ‚îî‚îÄ‚ñ∂ EdgeTTS (Microsoft) [Streaming]               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                   ‚îÇ                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ        Audio Response (OPUS encoded)                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ        Send back via WebSocket                          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ        HTTP Server (Port 8003)                          ‚îÇ‚îÇ
‚îÇ  ‚îÇ        - OTA firmware updates                           ‚îÇ‚îÇ
‚îÇ  ‚îÇ        - Vision analysis API                            ‚îÇ‚îÇ
‚îÇ  ‚îÇ        (core/http_server.py)                            ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2. Chi ti·∫øt c√°c module ch√≠nh

#### 2.2.1. Entry Point (`app.py`)

**Ch·ª©c nƒÉng**:
- Kh·ªüi ƒë·ªông asyncio event loop
- Load config t·ª´ `data/.config.yaml` ho·∫∑c `config.yaml`
- Kh·ªüi ƒë·ªông WebSocket server v√† HTTP server song song
- X·ª≠ l√Ω graceful shutdown

**Code flow**:
```python
async def main():
    check_ffmpeg_installed()           # Ki·ªÉm tra ffmpeg
    config = load_config()             # Load config
    
    # Kh·ªüi t·∫°o servers
    ws_server = WebSocketServer(config)
    ota_server = SimpleHttpServer(config)
    
    # Start servers concurrently
    ws_task = asyncio.create_task(ws_server.start())
    ota_task = asyncio.create_task(ota_server.start())
    
    await wait_for_exit()              # Block until SIGTERM/Ctrl-C
```

#### 2.2.2. WebSocket Server (`core/websocket_server.py`)

**Ch·ª©c nƒÉng**:
- L·∫Øng nghe k·∫øt n·ªëi WebSocket t·ª´ ESP32
- T·∫°o `Connection` instance cho m·ªói client
- Qu·∫£n l√Ω lifecycle c·ªßa connections

**Key methods**:
```python
class WebSocketServer:
    async def start(self):
        # Start WebSocket server on port 8000
        async with websockets.serve(
            self.handler, 
            self.ip, 
            self.port
        ):
            await asyncio.Future()  # Run forever
    
    async def handler(self, websocket, path):
        # Create connection instance
        connection = Connection(websocket, self.config)
        await connection.handle()
```

#### 2.2.3. Connection Handler (`core/connection.py`)

**Ch·ª©c nƒÉng**: X·ª≠ l√Ω to√†n b·ªô pipeline cho 1 k·∫øt n·ªëi

**Pipeline stages**:

1. **Receive Audio Stream**: Nh·∫≠n OPUS audio frames t·ª´ ESP32
2. **VAD Processing**: Ph√°t hi·ªán khi n√†o ng∆∞·ªùi d√πng b·∫Øt ƒë·∫ßu/k·∫øt th√∫c n√≥i
3. **ASR Processing**: Chuy·ªÉn audio ‚Üí text
4. **Intent Recognition**: Ph√¢n lo·∫°i intent (music, weather, chat, exit...)
5. **LLM Processing**: T·∫°o response text
6. **TTS Processing**: Chuy·ªÉn text ‚Üí audio
7. **Send Response**: G·ª≠i audio v·ªÅ ESP32

**Code structure**:
```python
class Connection:
    async def handle(self):
        while True:
            # Receive audio frame
            frame = await self.websocket.recv()
            
            # VAD: Check if speaking
            if self.vad_provider.is_speech(frame):
                self.audio_buffer.append(frame)
            else:
                # End of speech detected
                if self.audio_buffer:
                    await self.process_speech()
    
    async def process_speech(self):
        # 1. ASR
        text = await self.asr_provider.transcribe(audio_buffer)
        
        # 2. Intent
        intent = await self.intent_provider.recognize(text)
        
        # 3. LLM
        response = await self.llm_provider.chat(text, intent)
        
        # 4. TTS
        audio = await self.tts_provider.synthesize(response)
        
        # 5. Send back
        await self.websocket.send(audio)
```

#### 2.2.4. Providers (`core/providers/`)

**C·∫•u tr√∫c**:
```
core/providers/
‚îú‚îÄ‚îÄ asr/              # Speech Recognition
‚îÇ   ‚îú‚îÄ‚îÄ fun_asr.py    # FunASR local (GPU)
‚îÇ   ‚îú‚îÄ‚îÄ doubao_asr.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ tts/              # Text-to-Speech
‚îÇ   ‚îú‚îÄ‚îÄ edge_tts.py   # EdgeTTS (free)
‚îÇ   ‚îú‚îÄ‚îÄ doubao_tts.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ llm/              # Language Models
‚îÇ   ‚îú‚îÄ‚îÄ gemini_llm.py # Google Gemini
‚îÇ   ‚îú‚îÄ‚îÄ chatglm_llm.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ vad/              # Voice Activity Detection
‚îÇ   ‚îî‚îÄ‚îÄ silero_vad.py
‚îú‚îÄ‚îÄ intent/           # Intent Recognition
‚îÇ   ‚îú‚îÄ‚îÄ function_call.py
‚îÇ   ‚îî‚îÄ‚îÄ intent_llm.py
‚îî‚îÄ‚îÄ memory/           # Conversation Memory
    ‚îú‚îÄ‚îÄ nomem.py
    ‚îî‚îÄ‚îÄ mem0ai.py
```

**Provider pattern**: M·ªói provider implement interface chu·∫©n

```python
# Example: ASR Provider
class ASRProvider(ABC):
    @abstractmethod
    async def transcribe(self, audio_data: bytes) -> str:
        """Convert audio to text"""
        pass

# FunASR implementation
class FunASR(ASRProvider):
    def __init__(self, config):
        self.model = self.load_model(config['model_dir'])
        if torch.cuda.is_available():
            self.model = self.model.cuda()  # GPU acceleration
    
    async def transcribe(self, audio_data: bytes) -> str:
        # Decode OPUS ‚Üí PCM
        pcm = decode_opus(audio_data)
        
        # Run inference on GPU
        with torch.no_grad():
            result = self.model(pcm)
        
        return result['text']
```

#### 2.2.5. Plugin System (`plugins_func/functions/`)

**Ch·ª©c nƒÉng**: M·ªü r·ªông kh·∫£ nƒÉng c·ªßa robot qua function calling

**Available plugins**:
```
plugins_func/functions/
‚îú‚îÄ‚îÄ get_weather.py           # L·∫•y th√¥ng tin th·ªùi ti·∫øt
‚îú‚îÄ‚îÄ get_news_from_newsnow.py # ƒê·ªçc tin t·ª©c
‚îú‚îÄ‚îÄ play_music.py            # Ph√°t nh·∫°c t·ª´ th∆∞ m·ª•c
‚îú‚îÄ‚îÄ change_role.py           # ƒê·ªïi nh√¢n c√°ch
‚îú‚îÄ‚îÄ hass_get_state.py        # Home Assistant control
‚îî‚îÄ‚îÄ ...
```

**Plugin structure**:
```python
# Example: get_weather.py
async def get_weather(location: str = None) -> str:
    """
    L·∫•y th√¥ng tin th·ªùi ti·∫øt
    
    Args:
        location: T√™n th√†nh ph·ªë (n·∫øu kh√¥ng c√≥ d√πng default)
    
    Returns:
        Th√¥ng tin th·ªùi ti·∫øt d·∫°ng text
    """
    api_key = config['plugins']['get_weather']['api_key']
    url = f"https://api.qweather.com/v7/weather/now"
    
    response = await httpx.get(url, params={
        'location': location,
        'key': api_key
    })
    
    data = response.json()
    return format_weather(data)

# Function metadata for LLM
FUNCTION_SCHEMA = {
    "name": "get_weather",
    "description": "L·∫•y th√¥ng tin th·ªùi ti·∫øt hi·ªán t·∫°i",
    "parameters": {
        "type": "object",
        "properties": {
            "location": {
                "type": "string",
                "description": "T√™n th√†nh ph·ªë"
            }
        }
    }
}
```

### 2.3. Data Flow chi ti·∫øt

```
[ESP32 Audio Stream]
        ‚îÇ
        ‚ñº
[WebSocket Receive] ‚îÄ‚îÄ‚îê
        ‚îÇ             ‚îÇ
        ‚ñº             ‚îÇ Continuous streaming
[OPUS Decode]         ‚îÇ
        ‚îÇ             ‚îÇ
        ‚ñº             ‚îÇ
[VAD Detection] ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚îú‚îÄ‚ñ∂ [Silence] ‚îÄ‚îÄ‚ñ∂ Continue buffering
        ‚îÇ
        ‚îú‚îÄ‚ñ∂ [Speech Start] ‚îÄ‚îÄ‚ñ∂ Start recording
        ‚îÇ
        ‚îî‚îÄ‚ñ∂ [Speech End] ‚îÄ‚îÄ‚ñ∂ Process pipeline
                              ‚îÇ
                              ‚ñº
                        [Audio Buffer]
                              ‚îÇ
                              ‚ñº
                        [ASR: FunASR]
                        - Decode audio
                        - GPU inference
                        - Return text
                              ‚îÇ
                              ‚ñº
                        [Text: "‰ªäÂ§©Â§©Ê∞îÊÄé‰πàÊ†∑"]
                              ‚îÇ
                              ‚ñº
                        [Intent Recognition]
                        - Parse intent
                        - Check wake word
                        - Detect function call
                              ‚îÇ
                              ‚îú‚îÄ‚ñ∂ [Exit] ‚îÄ‚îÄ‚ñ∂ Close connection
                              ‚îÇ
                              ‚îú‚îÄ‚ñ∂ [Function Call]
                              ‚îÇ        ‚îÇ
                              ‚îÇ        ‚ñº
                              ‚îÇ   [Execute Plugin]
                              ‚îÇ   (e.g. get_weather)
                              ‚îÇ        ‚îÇ
                              ‚îÇ        ‚ñº
                              ‚îÇ   [Function Result]
                              ‚îÇ        ‚îÇ
                              ‚îÇ        ‚îî‚îÄ‚îÄ‚ñ∂ [Merge with context]
                              ‚îÇ
                              ‚ñº
                        [LLM Processing]
                        - Send to Gemini API
                        - Get response
                              ‚îÇ
                              ‚ñº
                        [Response Text: "‰ªäÂ§©ÂπøÂ∑û...]
                              ‚îÇ
                              ‚ñº
                        [TTS: EdgeTTS]
                        - Streaming synthesis
                        - Convert to OPUS
                              ‚îÇ
                              ‚ñº
                        [Audio Frames]
                              ‚îÇ
                              ‚ñº
                        [WebSocket Send]
                              ‚îÇ
                              ‚ñº
                        [ESP32 Speaker]
```

### 2.4. Concurrent Processing

Server s·ª≠ d·ª•ng Python `asyncio` ƒë·ªÉ x·ª≠ l√Ω concurrent connections:

```python
# Multiple ESP32 devices can connect simultaneously
connections = []

async def handle_connection(websocket):
    connection = Connection(websocket, config)
    connections.append(connection)
    
    try:
        await connection.handle()  # Each runs independently
    finally:
        connections.remove(connection)

# Server can handle 10-50 concurrent connections
# Limited by GPU memory for ASR processing
```

**Resource sharing**:
- **VAD model**: Loaded once, shared by all connections (lightweight)
- **ASR model**: Loaded once, GPU inference serialized via semaphore
- **LLM**: API calls, naturally concurrent
- **TTS**: Streaming, concurrent processing

**GPU memory management**:
```python
# ASR processing v·ªõi semaphore ƒë·ªÉ tr√°nh OOM
asr_semaphore = asyncio.Semaphore(2)  # Max 2 concurrent ASR

async def transcribe(audio):
    async with asr_semaphore:
        # Only 2 ASR operations at a time on GPU
        result = await self.asr_model(audio)
    return result
```

---

## 3. CONFIGURATION & CUSTOMIZATION

### 3.1. Config file structure

Server ƒë·ªçc config theo th·ª© t·ª± ∆∞u ti√™n:
1. `data/.config.yaml` (highest priority - your custom config)
2. `config.yaml` (fallback - default config)

**Best practice**: Ch·ªâ ƒë∆∞a nh·ªØng config c·∫ßn override v√†o `data/.config.yaml`

### 3.2. Optimal configuration cho GTX 1060

T·∫°o file `data/.config.yaml` v·ªõi n·ªôi dung sau:

```yaml
# ============================================================
# XiaoZhi Server Configuration
# Optimized for: GTX 1060 6GB, 16GB RAM, 6 cores
# Strategy: Local ASR+TTS, Gemini LLM
# ============================================================

# --------------------- Server Settings ---------------------
server:
  ip: 0.0.0.0
  port: 8000
  http_port: 8003
  # Thay YOUR_LOCAL_IP b·∫±ng IP th·ª±c c·ªßa PC (vd: 192.168.1.100)
  websocket: ws://YOUR_LOCAL_IP:8000/xiaozhi/v1/
  vision_explain: http://YOUR_LOCAL_IP:8003/mcp/vision/explain
  
  # Timezone offset for Vietnam
  timezone_offset: +7
  
  # Authentication (optional - disable for local testing)
  auth:
    enabled: false

# --------------------- Logging Settings ---------------------
log:
  log_level: INFO  # Change to DEBUG for troubleshooting
  log_dir: tmp
  log_file: "server.log"

# --------------------- Performance Tuning ---------------------
# X√≥a audio sau khi d√πng ƒë·ªÉ ti·∫øt ki·ªám disk
delete_audio: true

# Timeout cho TTS (tƒÉng l√™n n·∫øu m·∫°ng ch·∫≠m)
tts_timeout: 10

# ƒê√≥ng connection sau 2 ph√∫t kh√¥ng c√≥ audio
close_connection_no_voice_time: 120

# Enable wakeup word caching ƒë·ªÉ tƒÉng t·ªëc
enable_wakeup_words_response_cache: true

# TTS audio send delay (0 = auto, based on frame rate)
tts_audio_send_delay: 0

# --------------------- AI Personality ---------------------
prompt: |
  B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh, th√¢n thi·ªán v√† h·ªØu √≠ch.
  B·∫°n tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch, d·ªÖ hi·ªÉu.
  B·∫°n c√≥ th·ªÉ n√≥i ti·∫øng Vi·ªát v√† ti·∫øng Anh.
  Khi ƒë∆∞·ª£c h·ªèi v·ªÅ th·ªùi ti·∫øt, tin t·ª©c, b·∫°n s·ª≠ d·ª•ng tools ƒë·ªÉ l·∫•y th√¥ng tin.

# --------------------- Module Selection ---------------------
selected_module:
  VAD: SileroVAD          # Voice activity detection
  ASR: FunASR             # Local ASR with GPU
  LLM: GeminiLLM          # Google Gemini API
  TTS: EdgeTTS            # Microsoft Edge TTS (free, streaming)
  Memory: nomem           # No memory for faster response
  Intent: function_call   # Function calling for plugins

# --------------------- VAD Configuration ---------------------
VAD:
  SileroVAD:
    type: silero
    threshold: 0.5        # Speech detection threshold
    threshold_low: 0.3    # Lower threshold for continuation
    model_dir: models/snakers4_silero-vad
    min_silence_duration_ms: 200  # TƒÉng l√™n 300-400 n·∫øu b·ªã c·∫Øt gi·ªØa c√¢u

# --------------------- ASR Configuration ---------------------
ASR:
  FunASR:
    type: fun_local
    model_dir: models/SenseVoiceSmall
    output_dir: tmp/
    # GPU will be auto-detected and used if available

# --------------------- LLM Configuration ---------------------
LLM:
  GeminiLLM:
    type: gemini
    # Get your API key from: https://aistudio.google.com/apikey
    api_key: YOUR_GEMINI_API_KEY_HERE
    model_name: "gemini-2.0-flash-exp"  # Fast & free model
    # N·∫øu kh√¥ng truy c·∫≠p ƒë∆∞·ª£c t·ª´ VN, b·∫≠t proxy:
    # http_proxy: "http://127.0.0.1:7890"
    # https_proxy: "http://127.0.0.1:7890"

# --------------------- TTS Configuration ---------------------
TTS:
  EdgeTTS:
    type: edge
    # Vietnamese voices:
    # - vi-VN-HoaiMyNeural (Female)
    # - vi-VN-NamMinhNeural (Male)
    voice: vi-VN-HoaiMyNeural
    output_dir: tmp/

# --------------------- Intent Recognition ---------------------
Intent:
  function_call:
    type: function_call
    # Enabled plugins (comment out unused ones)
    functions:
      - get_weather         # Weather information
      - get_news_from_newsnow  # News
      - play_music          # Music playback (if you have music in ./music/)
      # - change_role       # Change AI personality
      # - hass_get_state    # Home Assistant (if configured)

# --------------------- Plugins Configuration ---------------------
plugins:
  get_weather:
    # Free API key for testing (limited requests)
    # Register your own at: https://console.qweather.com/#/apps/create-key/over
    api_host: "mj7p3y7naa.re.qweatherapi.com"
    api_key: "a861d0d5e7bf4ee1a83d9a9e4f96d4da"
    default_location: "Ho Chi Minh"  # Your city
  
  get_news_from_newsnow:
    url: "https://newsnow.busiyi.world/api/s?id="
    news_sources: "VnExpress;Tu·ªïi Tr·∫ª;Thanh Ni√™n"
  
  play_music:
    music_dir: "./music"
    music_ext:
      - ".mp3"
      - ".wav"
    refresh_time: 300

# --------------------- Wakeup Words ---------------------
wakeup_words:
  - "hey robot"
  - "xin ch√†o"
  - "hello"

# --------------------- Exit Commands ---------------------
exit_commands:
  - "t·∫°m bi·ªát"
  - "goodbye"
  - "exit"
```

### 3.3. Alternative TTS Options

N·∫øu EdgeTTS c√≥ ƒë·ªô tr·ªÖ cao, th·ª≠ c√°c options sau:

#### Option 1: LinkeraiTTS (Free, streaming, Chinese service)

```yaml
selected_module:
  TTS: LinkeraiTTS

TTS:
  LinkeraiTTS:
    type: linkerai
    api_url: https://tts.linkerai.cn/tts
    audio_format: "pcm"
    access_token: "U4YdYXVfpwWnk2t5Gp822zWPCuORyeJL"  # Free testing token
    voice: "OUeAo1mhq6IBExi"
    output_dir: tmp/
```

#### Option 2: Local TTS v·ªõi Fish-Speech (Requires more GPU RAM)

```bash
# C√†i ƒë·∫∑t Fish-Speech server (requires ~4GB GPU RAM)
docker pull fishaudio/fish-speech:latest
docker run -d -p 8080:8080 --gpus all fishaudio/fish-speech:latest

# Config
```

```yaml
selected_module:
  TTS: FishSpeech

TTS:
  FishSpeech:
    type: fishspeech
    api_url: "http://127.0.0.1:8080/v1/tts"
    api_key: "your_key"
    output_dir: tmp/
    # Voice cloning: Upload reference audio
    reference_audio: ["config/assets/my_voice.wav"]
    reference_text: ["ƒê√¢y l√† gi·ªçng n√≥i m·∫´u c·ªßa t√¥i"]
```

### 3.4. Advanced Customization

#### 3.4.1. Custom Plugin Development

T·∫°o plugin m·ªõi trong `plugins_func/functions/`:

```python
# plugins_func/functions/get_crypto_price.py

import httpx
from typing import Optional

async def get_crypto_price(symbol: str = "BTC") -> str:
    """
    L·∫•y gi√° cryptocurrency hi·ªán t·∫°i
    
    Args:
        symbol: M√£ coin (BTC, ETH, BNB...)
    
    Returns:
        Th√¥ng tin gi√° coin
    """
    url = f"https://api.binance.com/api/v3/ticker/price"
    
    async with httpx.AsyncClient() as client:
        response = await client.get(url, params={
            'symbol': f'{symbol.upper()}USDT'
        })
        
        if response.status_code == 200:
            data = response.json()
            price = float(data['price'])
            return f"{symbol} hi·ªán ƒëang {price:,.2f} USDT"
        else:
            return f"Kh√¥ng t√¨m th·∫•y gi√° cho {symbol}"

# Function schema cho LLM function calling
FUNCTION_SCHEMA = {
    "type": "function",
    "function": {
        "name": "get_crypto_price",
        "description": "L·∫•y gi√° cryptocurrency hi·ªán t·∫°i t·ª´ Binance",
        "parameters": {
            "type": "object",
            "properties": {
                "symbol": {
                    "type": "string",
                    "description": "M√£ cryptocurrency (VD: BTC, ETH, BNB)",
                    "enum": ["BTC", "ETH", "BNB", "SOL", "ADA"]
                }
            },
            "required": []
        }
    }
}
```

Th√™m v√†o config:

```yaml
Intent:
  function_call:
    functions:
      - get_weather
      - get_crypto_price  # Your new plugin
```

#### 3.4.2. Custom LLM Provider

T·∫°o provider cho local LLM (VD: Ollama):

```python
# core/providers/llm/ollama_llm.py

import httpx
from typing import AsyncIterator
from .base import LLMProvider

class OllamaLLM(LLMProvider):
    def __init__(self, config):
        self.base_url = config.get('base_url', 'http://localhost:11434')
        self.model = config.get('model_name', 'llama3.2:3b')
    
    async def chat(
        self, 
        messages: list,
        stream: bool = True
    ) -> AsyncIterator[str]:
        """
        Chat v·ªõi Ollama local model
        """
        url = f"{self.base_url}/api/chat"
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            async with client.stream(
                'POST',
                url,
                json={
                    'model': self.model,
                    'messages': messages,
                    'stream': stream
                }
            ) as response:
                async for line in response.aiter_lines():
                    if line:
                        data = json.loads(line)
                        if 'message' in data:
                            yield data['message']['content']
```

Config:

```yaml
selected_module:
  LLM: OllamaLLM

LLM:
  OllamaLLM:
    type: ollama
    base_url: http://localhost:11434
    model_name: qwen2.5:3b  # Lightweight model for 6GB GPU
```

#### 3.4.3. Performance Tuning Tips

**1. GPU Memory Management**

```python
# Modify core/providers/asr/fun_asr.py

# Reduce batch size if OOM
self.batch_size = 1  # Process 1 audio at a time

# Enable FP16 inference
if torch.cuda.is_available():
    self.model = self.model.half()  # FP16 -> 2x faster, 2x less VRAM
```

**2. VAD Tuning**

```yaml
VAD:
  SileroVAD:
    threshold: 0.4              # Lower = more sensitive (detect softer voice)
    threshold_low: 0.2          # Lower boundary
    min_silence_duration_ms: 300  # Longer silence before cutting
```

**3. Connection Pooling**

```python
# Modify core/connection.py

# Reuse HTTP clients
from httpx import AsyncClient

class Connection:
    def __init__(self):
        self.http_client = AsyncClient(
            timeout=30.0,
            limits=httpx.Limits(
                max_connections=100,
                max_keepalive_connections=20
            )
        )
```

### 3.5. Environment Variables

T·∫°o file `.env` ƒë·ªÉ qu·∫£n l√Ω secrets:

```bash
# .env
GEMINI_API_KEY=your_actual_api_key_here
WEATHER_API_KEY=your_weather_key
```

Load trong code:

```python
# config/config_loader.py
import os
from dotenv import load_dotenv

load_dotenv()

def load_config():
    config = load_yaml()
    
    # Override with env vars
    if 'LLM' in config and 'GeminiLLM' in config['LLM']:
        config['LLM']['GeminiLLM']['api_key'] = os.getenv(
            'GEMINI_API_KEY',
            config['LLM']['GeminiLLM']['api_key']
        )
    
    return config
```

---

## 4. ESP32-C3 CONFIGURATION

### 4.1. Ph∆∞∆°ng √°n A: S·ª≠ d·ª•ng Firmware c√≥ s·∫µn (Recommended)

#### 4.1.1. Flash firmware t·ª´ XiaoZhi

```bash
# Download firmware t·ª´ releases
wget https://github.com/78/xiaozhi-esp32/releases/latest/download/xiaozhi-esp32-c3.bin

# Flash v·ªõi esptool
pip install esptool

# T√¨m serial port
ls /dev/ttyUSB*  # ho·∫∑c /dev/ttyACM*

# Flash
esptool.py --chip esp32c3 --port /dev/ttyUSB0 --baud 460800 \
  write_flash -z 0x0 xiaozhi-esp32-c3.bin

# Monitor
esptool.py --chip esp32c3 --port /dev/ttyUSB0 monitor
```

#### 4.1.2. C·∫•u h√¨nh qua Web Interface

1. **K·∫øt n·ªëi WiFi**:
   - ESP32 s·∫Ω t·∫°o AP: `XiaoZhi-XXXXXX`
   - K·∫øt n·ªëi v√†o AP n√†y
   - M·ªü browser: `http://192.168.4.1`

2. **Config WiFi**:
   - Ch·ªçn WiFi network c·ªßa b·∫°n
   - Nh·∫≠p password
   - Save & Reboot

3. **Config Server**:
   - Sau khi reboot, ESP32 s·∫Ω k·∫øt n·ªëi WiFi nh√†
   - T√¨m IP c·ªßa ESP32 qua router ho·∫∑c serial monitor
   - Truy c·∫≠p: `http://<ESP32_IP>`
   - V√†o tab "Server Settings"
   - Nh·∫≠p WebSocket URL: `ws://YOUR_PC_IP:8000/xiaozhi/v1/`
   - Save

4. **Test**:
   - Nh·∫•n n√∫t Boot tr√™n ESP32 ƒë·ªÉ trigger wake word
   - N√≥i: "Hello"
   - Ki·ªÉm tra logs server

### 4.2. Ph∆∞∆°ng √°n B: T·ª± build firmware (Advanced)

#### 4.2.1. Setup ESP-IDF

```bash
# Install dependencies
sudo apt-get install git wget flex bison gperf python3 python3-pip \
  python3-venv cmake ninja-build ccache libffi-dev libssl-dev \
  dfu-util libusb-1.0-0

# Clone ESP-IDF
mkdir -p ~/esp
cd ~/esp
git clone --recursive https://github.com/espressif/esp-idf.git
cd esp-idf
git checkout v5.1.2

# Install
./install.sh esp32c3

# Setup env
. ./export.sh
```

#### 4.2.2. Clone XiaoZhi ESP32 project

```bash
cd ~/esp
git clone https://github.com/78/xiaozhi-esp32.git
cd xiaozhi-esp32
```

#### 4.2.3. Configure

```bash
# Open menuconfig
idf.py menuconfig

# Navigate to "XiaoZhi Configuration"
# Set:
# - WiFi SSID: your_wifi_name
# - WiFi Password: your_password
# - Server URL: ws://YOUR_PC_IP:8000/xiaozhi/v1/

# Save and exit
```

#### 4.2.4. Build & Flash

```bash
# Build
idf.py build

# Flash
idf.py -p /dev/ttyUSB0 flash

# Monitor
idf.py -p /dev/ttyUSB0 monitor
```

### 4.3. Firmware Configuration Files

ESP32 firmware config ƒë∆∞·ª£c l∆∞u trong flash:

```
/spiffs/config.json
{
  "wifi": {
    "ssid": "YourWiFi",
    "password": "password"
  },
  "server": {
    "url": "ws://192.168.1.100:8000/xiaozhi/v1/",
    "token": "optional_auth_token"
  },
  "audio": {
    "sample_rate": 16000,
    "channels": 1,
    "format": "opus"
  }
}
```

### 4.4. Network Considerations

#### 4.4.1. Local Network Setup

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   WiFi Router   ‚îÇ
‚îÇ  192.168.1.1    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ             ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  PC       ‚îÇ ‚îÇ  ESP32-C3   ‚îÇ
    ‚îÇ192.168.1.x‚îÇ ‚îÇ 192.168.1.y ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Requirements**:
- PC v√† ESP32 c√πng subnet
- Firewall cho ph√©p port 8000, 8003
- Router kh√¥ng block WebSocket traffic

#### 4.4.2. Firewall Configuration

```bash
# Ubuntu: Allow ports
sudo ufw allow 8000/tcp
sudo ufw allow 8003/tcp
sudo ufw reload

# Check
sudo ufw status
```

#### 4.4.3. Test Connection t·ª´ ESP32

```bash
# T·ª´ ESP32 serial monitor:
> ping 192.168.1.100  # Your PC IP

# Should see:
# 64 bytes from 192.168.1.100: icmp_seq=1 ttl=64 time=2 ms
```

### 4.5. OTA Updates

Server cung c·∫•p OTA endpoint:

```
http://YOUR_PC_IP:8003/xiaozhi/ota/
```

**C√°ch update firmware OTA**:

1. Build firmware m·ªõi
2. Upload l√™n server:
```bash
cp build/xiaozhi-esp32.bin main/xiaozhi-server/data/firmware.bin
```

3. Trigger OTA t·ª´ ESP32:
   - Web UI: Settings ‚Üí OTA Update
   - Ho·∫∑c REST API:
```bash
curl -X POST http://<ESP32_IP>/api/ota \
  -d '{"url": "http://YOUR_PC_IP:8003/xiaozhi/ota/firmware.bin"}'
```

---

## 5. TROUBLESHOOTING & PERFORMANCE

### 5.1. Common Issues

#### 5.1.1. CUDA Out of Memory

**Tri·ªáu ch·ª©ng**:
```
RuntimeError: CUDA out of memory. Tried to allocate XX MiB
```

**Solutions**:

1. Gi·∫£m concurrent connections:
```python
# core/websocket_server.py
MAX_CONNECTIONS = 2  # Reduce from default
```

2. Enable FP16:
```python
# core/providers/asr/fun_asr.py
self.model = self.model.half()  # Use FP16
```

3. Clear cache th∆∞·ªùng xuy√™n:
```python
import torch
torch.cuda.empty_cache()
```

#### 5.1.2. High Latency

**Symptoms**: Ph·∫£n h·ªìi ch·∫≠m > 3 gi√¢y

**Diagnosis**:
```python
# Add timing logs in core/connection.py
import time

start = time.time()
text = await self.asr_provider.transcribe(audio)
print(f"ASR took: {time.time() - start:.2f}s")

start = time.time()
response = await self.llm_provider.chat(text)
print(f"LLM took: {time.time() - start:.2f}s")

start = time.time()
audio = await self.tts_provider.synthesize(response)
print(f"TTS took: {time.time() - start:.2f}s")
```

**Bottlenecks & Solutions**:

1. **ASR slow (>1s)**:
   - Check GPU utilization: `nvidia-smi`
   - Ensure CUDA is used: `torch.cuda.is_available()`
   - Reduce audio buffer size

2. **LLM slow (>2s)**:
   - Check internet connection
   - Use faster model: `gemini-2.0-flash-exp`
   - Enable streaming response
   - Consider local LLM (Ollama)

3. **TTS slow (>1s)**:
   - Switch to streaming TTS (EdgeTTS, LinkeraiTTS)
   - Reduce response length (shorter prompts)

#### 5.1.3. Connection Drops

**Symptoms**: WebSocket disconnects frequently

**Causes & Solutions**:

1. **Network instability**:
```yaml
# Increase timeout in config
close_connection_no_voice_time: 300  # 5 minutes
```

2. **ESP32 WiFi issues**:
```c
// In ESP32 firmware: Increase WiFi power
esp_wifi_set_ps(WIFI_PS_NONE);  // Disable power saving
```

3. **Server overload**:
```python
# Monitor server load
import psutil
print(f"CPU: {psutil.cpu_percent()}%")
print(f"RAM: {psutil.virtual_memory().percent}%")
```

#### 5.1.4. Audio Quality Issues

**Problem**: Ti·∫øng b·ªã m√©o, nhi·ªÖu

**Solutions**:

1. **Check OPUS encoding**:
```yaml
xiaozhi:
  audio_params:
    format: opus
    sample_rate: 16000  # Don't change
    channels: 1         # Mono
    frame_duration: 60  # milliseconds
```

2. **Adjust VAD sensitivity**:
```yaml
VAD:
  SileroVAD:
    threshold: 0.5  # Higher = less sensitive, less noise
```

3. **Check network packet loss**:
```bash
# From server, ping ESP32
ping -c 100 <ESP32_IP>

# Check packet loss percentage
# Should be <1%
```

### 5.2. Performance Benchmarks

Expected latency on GTX 1060 setup:

| Component | Time | Notes |
|-----------|------|-------|
| VAD | <50ms | Per frame, CPU |
| ASR (FunASR GPU) | 200-500ms | Depends on audio length |
| Intent Recognition | <100ms | Function calling |
| LLM (Gemini) | 500-1500ms | Network dependent |
| TTS (EdgeTTS) | 300-800ms | Streaming, first chunk |
| **Total (avg)** | **1.5-3s** | From speech end to audio start |

**Optimization targets**:
- End-to-end latency: <2s
- GPU utilization: 30-60%
- RAM usage: <4GB
- CPU usage: <40%

### 5.3. Monitoring & Logging

#### 5.3.1. Enable Debug Logging

```yaml
log:
  log_level: DEBUG  # More detailed logs
```

#### 5.3.2. Performance Monitoring Script

T·∫°o `monitor.py`:

```python
#!/usr/bin/env python3
import psutil
import time
from rich.console import Console
from rich.table import Table

console = Console()

def monitor():
    while True:
        # GPU stats
        import subprocess
        gpu_info = subprocess.check_output(
            ['nvidia-smi', '--query-gpu=utilization.gpu,memory.used', 
             '--format=csv,noheader,nounits']
        ).decode().strip().split(',')
        
        gpu_util = gpu_info[0]
        gpu_mem = gpu_info[1]
        
        # System stats
        cpu = psutil.cpu_percent(interval=1)
        mem = psutil.virtual_memory()
        
        # Display
        table = Table(title="XiaoZhi Server Monitor")
        table.add_column("Metric")
        table.add_column("Value")
        
        table.add_row("CPU", f"{cpu}%")
        table.add_row("RAM", f"{mem.percent}% ({mem.used/1e9:.1f}GB/{mem.total/1e9:.1f}GB)")
        table.add_row("GPU Util", f"{gpu_util}%")
        table.add_row("GPU Mem", f"{gpu_mem}MB")
        
        console.clear()
        console.print(table)
        
        time.sleep(2)

if __name__ == '__main__':
    monitor()
```

Run:
```bash
python monitor.py
```

#### 5.3.3. Log Analysis

```bash
# View real-time logs
tail -f tmp/server.log

# Filter errors
grep ERROR tmp/server.log

# Count requests per minute
grep "ASR transcribe" tmp/server.log | awk '{print $1}' | uniq -c

# Average response time (if logged)
grep "Total latency" tmp/server.log | awk '{sum+=$NF; count++} END {print sum/count}'
```

### 5.4. Production Deployment Tips

#### 5.4.1. Use Process Manager

```bash
# Install supervisor
sudo apt-get install supervisor

# Create supervisor config
sudo nano /etc/supervisor/conf.d/xiaozhi.conf
```

```ini
[program:xiaozhi]
directory=/home/misa/Desktop/RD/xiaozhi-esp32-server/main/xiaozhi-server
command=/home/misa/miniconda3/envs/xiaozhi/bin/python app.py
user=misa
autostart=true
autorestart=true
stderr_logfile=/var/log/xiaozhi.err.log
stdout_logfile=/var/log/xiaozhi.out.log
```

```bash
# Start
sudo supervisorctl reread
sudo supervisorctl update
sudo supervisorctl start xiaozhi

# Check status
sudo supervisorctl status
```

#### 5.4.2. Auto-start on Boot

```bash
# Enable supervisor
sudo systemctl enable supervisor

# Verify
sudo systemctl status supervisor
```

#### 5.4.3. Backup Strategy

```bash
# Backup script
#!/bin/bash
DATE=$(date +%Y%m%d)
BACKUP_DIR="/home/misa/backups"

# Backup config
cp data/.config.yaml $BACKUP_DIR/config_$DATE.yaml

# Backup logs
tar -czf $BACKUP_DIR/logs_$DATE.tar.gz tmp/*.log

# Backup music library
tar -czf $BACKUP_DIR/music_$DATE.tar.gz music/

echo "Backup completed: $DATE"
```

#### 5.4.4. Security Hardening

```yaml
# Enable authentication
server:
  auth:
    enabled: true
    allowed_devices:
      - "AA:BB:CC:DD:EE:FF"  # Your ESP32 MAC address

# Generate secure auth key
import secrets
auth_key = secrets.token_hex(32)
```

### 5.5. Scaling Considerations

N·∫øu mu·ªën m·ªü r·ªông h·ªá th·ªëng:

1. **Multiple ESP32 devices** (5-10):
   - Current setup OK
   - Monitor GPU memory usage

2. **Many devices** (10-50):
   - Consider ASR API (FunASRServer)
   - Load balance with nginx

3. **Production scale** (50+):
   - Deploy Docker containers
   - Use Kubernetes for orchestration
   - Separate ASR/TTS/LLM microservices

---

## 6. QUICK REFERENCE

### 6.1. Start/Stop Commands

```bash
# Activate environment
conda activate xiaozhi

# Start server
cd ~/Desktop/RD/xiaozhi-esp32-server/main/xiaozhi-server
python app.py

# Stop server
Ctrl+C

# View logs
tail -f tmp/server.log

# Check GPU
nvidia-smi

# Monitor resources
htop
```

### 6.2. File Locations

```
~/Desktop/RD/xiaozhi-esp32-server/main/xiaozhi-server/
‚îú‚îÄ‚îÄ app.py                          # Entry point
‚îú‚îÄ‚îÄ config.yaml                     # Default config
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ .config.yaml               # Your custom config ‚≠ê
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ SenseVoiceSmall/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model.pt               # ASR model (400MB) ‚≠ê
‚îÇ   ‚îî‚îÄ‚îÄ snakers4_silero-vad/       # VAD model (auto-downloaded)
‚îú‚îÄ‚îÄ tmp/                            # Temp audio files
‚îÇ   ‚îî‚îÄ‚îÄ server.log                 # Main log file ‚≠ê
‚îú‚îÄ‚îÄ music/                          # Music library (optional)
‚îú‚îÄ‚îÄ core/                           # Core modules
‚îÇ   ‚îú‚îÄ‚îÄ websocket_server.py
‚îÇ   ‚îú‚îÄ‚îÄ connection.py
‚îÇ   ‚îî‚îÄ‚îÄ providers/
‚îÇ       ‚îú‚îÄ‚îÄ asr/
‚îÇ       ‚îú‚îÄ‚îÄ tts/
‚îÇ       ‚îú‚îÄ‚îÄ llm/
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ plugins_func/                   # Plugin functions
    ‚îî‚îÄ‚îÄ functions/
```

### 6.3. Port Reference

| Port | Service | Protocol | Purpose |
|------|---------|----------|---------|
| 8000 | WebSocket | WS | Main ESP32 communication |
| 8003 | HTTP | HTTP | OTA updates, Vision API |

### 6.4. API Endpoints

```
# WebSocket
ws://YOUR_IP:8000/xiaozhi/v1/

# OTA
http://YOUR_IP:8003/xiaozhi/ota/

# Vision Analysis
http://YOUR_IP:8003/mcp/vision/explain
```

### 6.5. Useful Commands

```bash
# Find your local IP
ip addr show | grep inet

# Test WebSocket
# Use browser: main/xiaozhi-server/test/test_page.html

# Check port listening
sudo netstat -tlnp | grep :8000

# Kill process on port
sudo fof -t -i:8000
sudo kill -9 <PID>

# Disk space
df -h

# GPU memory
nvidia-smi --query-gpu=memory.used,memory.total --format=csv
```

---

## 7. NEXT STEPS

### 7.1. After Successful Deployment

1. ‚úÖ **Test basic conversation**
2. ‚úÖ **Test function calling** (weather, news)
3. ‚¨ú **Customize AI personality** (edit prompt)
4. ‚¨ú **Add custom plugins**
5. ‚¨ú **Optimize for your use case**

### 7.2. Advanced Features to Explore

- **Voice cloning** v·ªõi Fish-Speech
- **Home Assistant integration** cho smart home control
- **Memory system** v·ªõi mem0ai
- **Vision capabilities** v·ªõi camera module
- **Multi-language support**

### 7.3. Contributing

N·∫øu b·∫°n ph√°t tri·ªÉn th√™m features hay t·ªëi ∆∞u:

1. Fork repo
2. T·∫°o branch: `git checkout -b feature/your-feature`
3. Commit: `git commit -m 'Add feature'`
4. Push: `git push origin feature/your-feature`
5. T·∫°o Pull Request

---

## 8. SUPPORT & RESOURCES

### Official Documentation
- GitHub: https://github.com/xinnan-tech/xiaozhi-esp32-server
- Docs: https://github.com/xinnan-tech/xiaozhi-esp32-server/tree/main/docs

### Community
- Issues: https://github.com/xinnan-tech/xiaozhi-esp32-server/issues
- Discussions: https://github.com/xinnan-tech/xiaozhi-esp32-server/discussions

### External Resources
- FunASR: https://github.com/modelscope/FunASR
- Gemini API: https://ai.google.dev/gemini-api/docs
- ESP-IDF: https://docs.espressif.com/projects/esp-idf/

---

**Document Version**: 1.0  
**Last Updated**: 2025-01-25  
**Author**: AI Assistant for XiaoZhi Deployment  
**Status**: Ready for Production Testing

---

*Good luck with your deployment! üöÄ*
